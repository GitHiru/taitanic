{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚢 環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the train data : (891, 12)\n",
      "The size of the test data : (418, 11)\n",
      "The size of the alldata data: (1309, 13)\n"
     ]
    }
   ],
   "source": [
    "train_raw = pd.read_csv('csv/train.csv') # read:学習データ\n",
    "test_raw = pd.read_csv('csv/test.csv')   # read:テストデータ\n",
    "print('The size of the train data :', train_raw.shape)\n",
    "print('The size of the test data :', test_raw.shape)\n",
    "\n",
    "train_mid = train_raw.copy()\n",
    "test_mid = test_raw.copy()\n",
    "train_mid['train_or_test'] = 'train' # add:学習データフラグ\n",
    "test_mid['train_or_test'] = 'test'   # add:テストデータフラグ\n",
    "test_mid['Survived'] = 9             # add:テストにSurvivedカラムを仮置き\n",
    "\n",
    "alldata = pd.concat([train_mid, test_mid], sort=False, axis=0).reset_index(drop=True)\n",
    "print('The size of the alldata data:', alldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚢 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 欠損値補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId         0\n",
       "Survived            0\n",
       "Pclass              0\n",
       "Name                0\n",
       "Sex                 0\n",
       "Age               263\n",
       "SibSp               0\n",
       "Parch               0\n",
       "Ticket              0\n",
       "Fare                1\n",
       "Cabin            1014\n",
       "Embarked            2\n",
       "train_or_test       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         0\n",
      "Survived            0\n",
      "Pclass              0\n",
      "Name                0\n",
      "Sex                 0\n",
      "Age               263\n",
      "SibSp               0\n",
      "Parch               0\n",
      "Ticket              0\n",
      "Fare                0\n",
      "Cabin            1014\n",
      "Embarked            0\n",
      "train_or_test       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Embarked(出港)には最頻値を代入\n",
    "alldata.Embarked.fillna(alldata.Embarked.mode()[0], inplace=True)\n",
    "# Fare(料金)には中央値を代入\n",
    "alldata.Fare.fillna(alldata.Fare.median(), inplace=True)\n",
    "# 欠損値補完がされたかを確認\n",
    "print(alldata.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 特徴量別加工"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ Parch / Sibsp\n",
    "（親,子供数 / 兄弟,配偶者数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familysize\n",
    "alldata['FamilySize'] = alldata['Parch'] + alldata['SibSp'] + 1\n",
    "# Familysize離散化：ビニング処理（ビン分割）\n",
    "alldata['FamilySize_bin'] = 'big' # add:8以上はbigとする\n",
    "alldata.loc[alldata['FamilySize']==1, 'FamilySize_bin'] = 'alone'\n",
    "alldata.loc[(alldata['FamilySize']>=2) & (alldata['FamilySize']<=4), 'FamilySize_bin'] = 'small'\n",
    "alldata.loc[(alldata['FamilySize']>=5) & (alldata['FamilySize']<=7), 'FamilySize_bin'] = 'mediam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ Ticket\n",
    "同じTicketを持っている乗客数(alldataにおけるTicketの出現頻度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.loc[:, 'TicketFreq'] = alldata.groupby(['Ticket'])['PassengerId'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ Name\n",
    "ミドルネーム（honorific）を特徴量とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの敬称（honorific）抽出\n",
    "alldata['honorific'] = alldata['Name'].map(lambda x: x.split(', ')[1].split('. ')[0])\n",
    "# 敬称（honorific）格好\n",
    "alldata['honorific'].replace(['Col', 'Dr', 'Rev'], 'Rare', inplace=True) # 少数派の敬称をRare統合\n",
    "alldata['honorific'].replace(['Mlle', 'Ms'], 'Miss', inplace=True) # Missに統合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ Fare\n",
    "    (運賃)外れ値が存在\n",
    "    ロバスト（頑健）なモデル構築を目的とするので、ビニング（分割）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.loc[:, 'Fare_bin'] = pd.qcut(alldata.Fare, 14) # 14分割（今回は任意設定）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ Cabin\n",
    "客室番号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabinの頭文字\n",
    "alldata['Cabin_ini'] = alldata['Cabin'].map(lambda x:str(x)[0])\n",
    "alldata['Cabin_ini'].replace(['G','T'], 'Rare',inplace=True) #少数派のCabin_iniを統合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>FamilySize_bin</th>\n",
       "      <th>TicketFreq</th>\n",
       "      <th>honorific</th>\n",
       "      <th>Fare_bin</th>\n",
       "      <th>Cabin_ini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.229, 7.75]</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(59.4, 90.0]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>alone</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(7.879, 8.05]</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(39.0, 59.4]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>alone</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.879, 8.05]</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked train_or_test  FamilySize  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S         train           2   \n",
       "1      0          PC 17599  71.2833   C85        C         train           2   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S         train           1   \n",
       "3      0            113803  53.1000  C123        S         train           2   \n",
       "4      0            373450   8.0500   NaN        S         train           1   \n",
       "\n",
       "  FamilySize_bin  TicketFreq honorific       Fare_bin Cabin_ini  \n",
       "0          small           1        Mr  (7.229, 7.75]         n  \n",
       "1          small           2       Mrs   (59.4, 90.0]         C  \n",
       "2          alone           1      Miss  (7.879, 8.05]         n  \n",
       "3          small           2       Mrs   (39.0, 59.4]         C  \n",
       "4          alone           1        Mr  (7.879, 8.05]         n  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId          int64\n",
       "Survived             int64\n",
       "Pclass               int64\n",
       "Name                object\n",
       "Sex                 object\n",
       "Age                float64\n",
       "SibSp                int64\n",
       "Parch                int64\n",
       "Ticket              object\n",
       "Fare               float64\n",
       "Cabin               object\n",
       "Embarked            object\n",
       "train_or_test       object\n",
       "FamilySize           int64\n",
       "FamilySize_bin      object\n",
       "TicketFreq           int64\n",
       "honorific           object\n",
       "Fare_bin          category\n",
       "Cabin_ini           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PclassをObject型に変換 ∵カテゴリカル変数のPclassが整数型になっているので、文字列に変換\n",
    "alldata.Pclass = alldata.Pclass.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ特徴量について Label-Encoding を施す\n",
    "le_target_col = ['Sex', 'Fare_bin']\n",
    "le = LabelEncoder()\n",
    "for col in le_target_col:\n",
    "    alldata.loc[:, col] = le.fit_transform(alldata[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカル変数 One-Hot-Encoding を施す\n",
    "cat_col = ['Pclass', 'Embarked','honorific','Cabin_ini', 'FamilySize_bin', 'Fare_bin']\n",
    "alldata = pd.get_dummies(alldata, drop_first=True, columns=cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'train_or_test', 'FamilySize', 'TicketFreq',\n",
       "       'Pclass_2', 'Pclass_3', 'Embarked_Q', 'Embarked_S', 'honorific_Don',\n",
       "       'honorific_Dona', 'honorific_Jonkheer', 'honorific_Lady',\n",
       "       'honorific_Major', 'honorific_Master', 'honorific_Miss',\n",
       "       'honorific_Mme', 'honorific_Mr', 'honorific_Mrs', 'honorific_Rare',\n",
       "       'honorific_Sir', 'honorific_the Countess', 'Cabin_ini_B', 'Cabin_ini_C',\n",
       "       'Cabin_ini_D', 'Cabin_ini_E', 'Cabin_ini_F', 'Cabin_ini_Rare',\n",
       "       'Cabin_ini_n', 'FamilySize_bin_big', 'FamilySize_bin_mediam',\n",
       "       'FamilySize_bin_small', 'Fare_bin_1', 'Fare_bin_2', 'Fare_bin_3',\n",
       "       'Fare_bin_4', 'Fare_bin_5', 'Fare_bin_6', 'Fare_bin_7', 'Fare_bin_8',\n",
       "       'Fare_bin_9', 'Fare_bin_10', 'Fare_bin_11', 'Fare_bin_12',\n",
       "       'Fare_bin_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚢 モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 最初に統合したtrainとtestを分離\n",
    "train = alldata.query('train_or_test == \"train\"')\n",
    "test = alldata.query('train_or_test == \"test\"')\n",
    "# ターゲット変数と、学習に不要なカラムを定義\n",
    "target_col = 'Survived'\n",
    "drop_col = ['PassengerId','Survived', 'Name', 'Fare', 'Ticket', 'Cabin', 'train_or_test', 'Age', 'Parch', 'FamilySize', 'SibSp']\n",
    "# 学習に必要な特徴量のみを保持\n",
    "train_feature = train.drop(columns=drop_col)\n",
    "test_feature = test.drop(columns=drop_col)\n",
    "train_tagert = train[target_col]\n",
    "# trainデータを分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_feature, train_tagert, test_size=0.2, random_state=0, stratify=train_tagert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ベースライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survive rate:0.38342696629213485\n",
      "base line accuracy: 0.6165730337078652\n"
     ]
    }
   ],
   "source": [
    "# trainから頻度に応じて単純なモデルを作る場合\n",
    "survive_rate = y_train.sum()/len(y_train)\n",
    "print(f'survive rate:{survive_rate}')\n",
    "print(f'base line accuracy: {1 - survive_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習モデルによる予測では、少なくともこのAccuracy62%を超えていないと話になりません。\n",
    "以下ではRandamForest、XGBoost、LightGBM、LogisticRegression、SVCの5つの機械学習モデルで学習データへの当てはめとテストデータへの汎化性能を確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.1.1-py2.py3-none-macosx_10_13_x86_64.macosx_10_14_x86_64.macosx_10_15_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from lightgbm) (1.5.4)\n",
      "Requirement already satisfied: numpy in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from lightgbm) (1.19.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: wheel, lightgbm\n",
      "Successfully installed lightgbm-3.1.1 wheel-0.36.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "RandomForestClassifier\n",
      "accuracy of train set: 0.9199438202247191\n",
      "accuracy of test set: 0.7821229050279329\n",
      "[11:30:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "====================\n",
      "XGBClassifier\n",
      "accuracy of train set: 0.9030898876404494\n",
      "accuracy of train set: 0.7877094972067039\n",
      "====================\n",
      "LGBMClassifier\n",
      "accuracy of train set: 0.8932584269662921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train set: 0.7988826815642458\n",
      "====================\n",
      "LogisticRegression\n",
      "accuracy of train set: 0.8426966292134831\n",
      "accuracy of train set: 0.8156424581005587\n",
      "====================\n",
      "SVC\n",
      "accuracy of train set: 0.8426966292134831\n",
      "accuracy of train set: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('='*20)\n",
    "print('RandomForestClassifier')\n",
    "print(f'accuracy of train set: {rfc.score(X_train, y_train)}')\n",
    "print(f'accuracy of test set: {rfc.score(X_test, y_test)}')\n",
    "\n",
    "xgb = XGBClassifier(random_state=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "print('='*20)\n",
    "print('XGBClassifier')\n",
    "print(f'accuracy of train set: {xgb.score(X_train, y_train)}')\n",
    "print(f'accuracy of train set: {xgb.score(X_test, y_test)}')\n",
    "\n",
    "lgb = LGBMClassifier(random_state=0)\n",
    "lgb.fit(X_train, y_train)\n",
    "print('='*20)\n",
    "print('LGBMClassifier')\n",
    "print(f'accuracy of train set: {lgb.score(X_train, y_train)}')\n",
    "print(f'accuracy of train set: {lgb.score(X_test, y_test)}')\n",
    "\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "print('='*20)\n",
    "print('LogisticRegression')\n",
    "print(f'accuracy of train set: {lr.score(X_train, y_train)}')\n",
    "print(f'accuracy of train set: {lr.score(X_test, y_test)}')\n",
    "\n",
    "svc = SVC(random_state=0)\n",
    "svc.fit(X_train, y_train)\n",
    "print('='*20)\n",
    "print('SVC')\n",
    "print(f'accuracy of train set: {svc.score(X_train, y_train)}')\n",
    "print(f'accuracy of train set: {svc.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RandomForestClassifier feature importance')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 試しにRandamForestClassifierの重要度を可視化する\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.barh(\n",
    "    X_train.columns[np.argsort(rfc.feature_importances_)],\n",
    "    rfc.feature_importances_[np.argsort(rfc.feature_importances_)],\n",
    "    label='RandomForestClassifier'\n",
    ")\n",
    "plt.title('RandomForestClassifier feature importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - パラメーターチューニング\n",
    "今回はscikit-learnのGridSearchCVではなく、Preferred Networks社が出しているハイパーパラメータ自動化ツールOptunaを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.3.0.tar.gz (258 kB)\n",
      "\u001b[K     |████████████████████████████████| 258 kB 766 kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from optuna) (20.4)\n",
      "Requirement already satisfied: joblib in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from optuna) (0.17.0)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from optuna) (1.5.4)\n",
      "Requirement already satisfied: tqdm in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from optuna) (4.54.1)\n",
      "Requirement already satisfied: numpy in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from optuna) (1.19.4)\n",
      "Collecting cmaes>=0.6.0\n",
      "  Downloading cmaes-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from packaging>=20.0->optuna) (1.15.0)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.3.22-cp38-cp38-macosx_10_14_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 611 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.4.3-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from alembic->optuna) (2.8.1)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.5.0-py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 561 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
      "  Downloading cmd2-1.4.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 546 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.2.0)\n",
      "Requirement already satisfied: colorama>=0.3.7 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.4)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
      "  Downloading prettytable-0.7.2.zip (28 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.1.tar.gz (20 kB)\n",
      "Collecting PyYAML>=3.12\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 588 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 352 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-4.6.2-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 1.0 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Building wheels for collected packages: optuna, PrettyTable, pyperclip, PyYAML\n",
      "  Building wheel for optuna (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optuna: filename=optuna-2.3.0-py3-none-any.whl size=359701 sha256=67f671a1bfff88890b0e4d1b19e3409d7017f61f79391557b2a3637b84aeee28\n",
      "  Stored in directory: /Users/t/Library/Caches/pip/wheels/90/cf/2a/6326fab045ea048eba2ebf4ffeb477b74e1c37639435ba0d0d\n",
      "  Building wheel for PrettyTable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PrettyTable: filename=prettytable-0.7.2-py3-none-any.whl size=13699 sha256=0c7b48a8e656e7fdd84152939141ea8447132b0f6dd78008b493e00ab003ea68\n",
      "  Stored in directory: /Users/t/Library/Caches/pip/wheels/48/6d/77/9517cb933af254f51a446f1a5ec9c2be3e45f17384940bce68\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.1-py3-none-any.whl size=11117 sha256=70091bea762f203b4ac355442e6fa5b310dd76845b2db970b4356823c88c597c\n",
      "  Stored in directory: /Users/t/Library/Caches/pip/wheels/67/0c/ba/1468f38115898442e13f99a19a8dcf1e0ca73488053ef7b388\n",
      "  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp38-cp38-macosx_10_15_x86_64.whl size=44624 sha256=0e26f6fc7db308c0bf4dbad45caf94162471d85969e6fb58f1ae897db74a48fc\n",
      "  Stored in directory: /Users/t/Library/Caches/pip/wheels/13/90/db/290ab3a34f2ef0b5a0f89235dc2d40fea83e77de84ed2dc05c\n",
      "Successfully built optuna PrettyTable pyperclip PyYAML\n",
      "Installing collected packages: pyperclip, pbr, stevedore, sqlalchemy, PyYAML, python-editor, PrettyTable, Mako, cmd2, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 PyYAML-5.3.1 alembic-1.4.3 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorlog-4.6.2 optuna-2.3.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 sqlalchemy-1.3.22 stevedore-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "import optuna\n",
    "\n",
    "# CV分割数(クロスバリデーション)\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:38:58,257]\u001b[0m A new study created in memory with name: no-name-fbd9bb04-fc7e-47d2-a53c-c9b3fcff04e2\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:38:59,128]\u001b[0m Trial 0 finished with value: 0.8356741849699596 and parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 6}. Best is trial 0 with value: 0.8356741849699596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:38:59,813]\u001b[0m Trial 1 finished with value: 0.8314586821629074 and parameters: {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 9, 'criterion': 'gini', 'max_features': 5}. Best is trial 0 with value: 0.8356741849699596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:00,454]\u001b[0m Trial 2 finished with value: 0.8328671328671329 and parameters: {'max_depth': 11, 'min_samples_leaf': 3, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 4}. Best is trial 0 with value: 0.8356741849699596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:01,118]\u001b[0m Trial 3 finished with value: 0.8300600807643062 and parameters: {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 7, 'criterion': 'gini', 'max_features': 6}. Best is trial 0 with value: 0.8356741849699596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:01,822]\u001b[0m Trial 4 finished with value: 0.8300502314586822 and parameters: {'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 15, 'criterion': 'entropy', 'max_features': 8}. Best is trial 0 with value: 0.8356741849699596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:02,479]\u001b[0m Trial 5 finished with value: 0.8399093863882596 and parameters: {'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 15, 'criterion': 'entropy', 'max_features': 6}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:03,101]\u001b[0m Trial 6 finished with value: 0.825844577957254 and parameters: {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'gini', 'max_features': 3}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:03,741]\u001b[0m Trial 7 finished with value: 0.8356643356643356 and parameters: {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 15, 'criterion': 'entropy', 'max_features': 7}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:04,391]\u001b[0m Trial 8 finished with value: 0.8384615384615384 and parameters: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 8}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:05,126]\u001b[0m Trial 9 finished with value: 0.8384812370727864 and parameters: {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 15, 'criterion': 'gini', 'max_features': 6}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:05,866]\u001b[0m Trial 10 finished with value: 0.8272530286614792 and parameters: {'max_depth': 15, 'min_samples_leaf': 5, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 9}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:06,498]\u001b[0m Trial 11 finished with value: 0.8342854328769821 and parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 4}. Best is trial 5 with value: 0.8399093863882596.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:07,175]\u001b[0m Trial 12 finished with value: 0.841317837092485 and parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 15, 'criterion': 'entropy', 'max_features': 7}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:07,858]\u001b[0m Trial 13 finished with value: 0.8398995370826355 and parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 8}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:08,542]\u001b[0m Trial 14 finished with value: 0.8385009356840343 and parameters: {'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 7}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:09,223]\u001b[0m Trial 15 finished with value: 0.841307987786861 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:09,939]\u001b[0m Trial 16 finished with value: 0.8384910863784102 and parameters: {'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:10,631]\u001b[0m Trial 17 finished with value: 0.841317837092485 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:11,304]\u001b[0m Trial 18 finished with value: 0.8286516300600809 and parameters: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 9}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:12,111]\u001b[0m Trial 19 finished with value: 0.8370924849798088 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 9}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:13,015]\u001b[0m Trial 20 finished with value: 0.8342854328769821 and parameters: {'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 10}. Best is trial 12 with value: 0.841317837092485.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:13,733]\u001b[0m Trial 21 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:14,492]\u001b[0m Trial 22 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:15,223]\u001b[0m Trial 23 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:15,944]\u001b[0m Trial 24 finished with value: 0.8398995370826355 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 9}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:16,674]\u001b[0m Trial 25 finished with value: 0.8328966807840047 and parameters: {'max_depth': 12, 'min_samples_leaf': 3, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:17,398]\u001b[0m Trial 26 finished with value: 0.8398995370826355 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 9}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:18,072]\u001b[0m Trial 27 finished with value: 0.8384910863784103 and parameters: {'max_depth': 11, 'min_samples_leaf': 2, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:18,740]\u001b[0m Trial 28 finished with value: 0.8328671328671329 and parameters: {'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 8}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:19,516]\u001b[0m Trial 29 finished with value: 0.8384812370727863 and parameters: {'max_depth': 11, 'min_samples_leaf': 2, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 9}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:20,355]\u001b[0m Trial 30 finished with value: 0.8342657342657344 and parameters: {'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:21,114]\u001b[0m Trial 31 finished with value: 0.837082635674185 and parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 7}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:21,850]\u001b[0m Trial 32 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:22,608]\u001b[0m Trial 33 finished with value: 0.8328966807840047 and parameters: {'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:23,316]\u001b[0m Trial 34 finished with value: 0.8398995370826355 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 9}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:24,051]\u001b[0m Trial 35 finished with value: 0.8398995370826355 and parameters: {'max_depth': 12, 'min_samples_leaf': 3, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:24,730]\u001b[0m Trial 36 finished with value: 0.8384713877671623 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 11, 'criterion': 'gini', 'max_features': 8}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:25,459]\u001b[0m Trial 37 finished with value: 0.8342952821826062 and parameters: {'max_depth': 14, 'min_samples_leaf': 3, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 9}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:26,098]\u001b[0m Trial 38 finished with value: 0.8356741849699596 and parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 5}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:26,773]\u001b[0m Trial 39 finished with value: 0.8356643356643356 and parameters: {'max_depth': 12, 'min_samples_leaf': 3, 'min_samples_split': 12, 'criterion': 'gini', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:27,446]\u001b[0m Trial 40 finished with value: 0.8399093863882596 and parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 9}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:28,129]\u001b[0m Trial 41 finished with value: 0.841317837092485 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:28,812]\u001b[0m Trial 42 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 21 with value: 0.8427164384910864.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:29,500]\u001b[0m Trial 43 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:30,195]\u001b[0m Trial 44 finished with value: 0.8314783807741556 and parameters: {'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:30,932]\u001b[0m Trial 45 finished with value: 0.8426868905742145 and parameters: {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:31,707]\u001b[0m Trial 46 finished with value: 0.8328671328671329 and parameters: {'max_depth': 14, 'min_samples_leaf': 3, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 8}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:32,411]\u001b[0m Trial 47 finished with value: 0.8272431793558553 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'gini', 'max_features': 3}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:33,187]\u001b[0m Trial 48 finished with value: 0.8384812370727864 and parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:33,897]\u001b[0m Trial 49 finished with value: 0.841298138481237 and parameters: {'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:34,599]\u001b[0m Trial 50 finished with value: 0.8398995370826355 and parameters: {'max_depth': 11, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 8}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:35,290]\u001b[0m Trial 51 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:35,991]\u001b[0m Trial 52 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:36,691]\u001b[0m Trial 53 finished with value: 0.8441248891953116 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:37,365]\u001b[0m Trial 54 finished with value: 0.8356840342755836 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:38,050]\u001b[0m Trial 55 finished with value: 0.8441248891953116 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:38,731]\u001b[0m Trial 56 finished with value: 0.8441248891953116 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:39,403]\u001b[0m Trial 57 finished with value: 0.8342755835713582 and parameters: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:40,097]\u001b[0m Trial 58 finished with value: 0.8384910863784103 and parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:40,780]\u001b[0m Trial 59 finished with value: 0.8427164384910864 and parameters: {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:41,426]\u001b[0m Trial 60 finished with value: 0.8356741849699596 and parameters: {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 15, 'criterion': 'gini', 'max_features': 5}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:42,106]\u001b[0m Trial 61 finished with value: 0.8441248891953116 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:42,793]\u001b[0m Trial 62 finished with value: 0.8398995370826355 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:43,468]\u001b[0m Trial 63 finished with value: 0.8356938835812077 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:44,212]\u001b[0m Trial 64 finished with value: 0.8398995370826355 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:44,922]\u001b[0m Trial 65 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:45,632]\u001b[0m Trial 66 finished with value: 0.8314685314685315 and parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:46,398]\u001b[0m Trial 67 finished with value: 0.8398995370826355 and parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:47,151]\u001b[0m Trial 68 finished with value: 0.841298138481237 and parameters: {'max_depth': 14, 'min_samples_leaf': 3, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:47,898]\u001b[0m Trial 69 finished with value: 0.8342854328769823 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:48,615]\u001b[0m Trial 70 finished with value: 0.8258544272628778 and parameters: {'max_depth': 14, 'min_samples_leaf': 5, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:49,317]\u001b[0m Trial 71 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:50,069]\u001b[0m Trial 72 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:50,798]\u001b[0m Trial 73 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:51,503]\u001b[0m Trial 74 finished with value: 0.8357037328868314 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 15, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:52,279]\u001b[0m Trial 75 finished with value: 0.8398995370826355 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:53,040]\u001b[0m Trial 76 finished with value: 0.8328769821727569 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:53,811]\u001b[0m Trial 77 finished with value: 0.8441150398896878 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:54,532]\u001b[0m Trial 78 finished with value: 0.8356938835812077 and parameters: {'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:55,331]\u001b[0m Trial 79 finished with value: 0.841307987786861 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:56,152]\u001b[0m Trial 80 finished with value: 0.841298138481237 and parameters: {'max_depth': 14, 'min_samples_leaf': 3, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:56,979]\u001b[0m Trial 81 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:57,742]\u001b[0m Trial 82 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:58,542]\u001b[0m Trial 83 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:59,241]\u001b[0m Trial 84 finished with value: 0.8441150398896878 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:39:59,943]\u001b[0m Trial 85 finished with value: 0.8328769821727569 and parameters: {'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:00,767]\u001b[0m Trial 86 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:01,478]\u001b[0m Trial 87 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:02,290]\u001b[0m Trial 88 finished with value: 0.841307987786861 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'gini', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:02,971]\u001b[0m Trial 89 finished with value: 0.8384812370727863 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:03,667]\u001b[0m Trial 90 finished with value: 0.841307987786861 and parameters: {'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:04,347]\u001b[0m Trial 91 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:04,992]\u001b[0m Trial 92 finished with value: 0.8385009356840343 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 4}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:05,675]\u001b[0m Trial 93 finished with value: 0.8469220919925146 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:06,444]\u001b[0m Trial 94 finished with value: 0.8441150398896878 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:07,182]\u001b[0m Trial 95 finished with value: 0.8427164384910864 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:07,929]\u001b[0m Trial 96 finished with value: 0.8441150398896878 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:08,655]\u001b[0m Trial 97 finished with value: 0.8398995370826355 and parameters: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 9}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:09,379]\u001b[0m Trial 98 finished with value: 0.8384713877671626 and parameters: {'max_depth': 14, 'min_samples_leaf': 3, 'min_samples_split': 14, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:40:10,204]\u001b[0m Trial 99 finished with value: 0.8441150398896878 and parameters: {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}. Best is trial 43 with value: 0.8469220919925146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 10}\n",
      "0.8469220919925146\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param_grid_rfc = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        'min_samples_split': trial.suggest_int(\"min_samples_split\", 7, 15),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        'max_features': trial.suggest_int(\"max_features\", 3, 10),\n",
    "        \"random_state\": 0\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**param_grid_rfc)\n",
    "    \n",
    "    # 5-Fold CV / Accuracy でモデルを評価する\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n",
    "    # 最小化なので 1.0 からスコアを引く\n",
    "    return scores['test_score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "rfc_best_param = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:33,752]\u001b[0m A new study created in memory with name: no-name-4b14031f-e7ed-417d-b06f-644d8e672330\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:34,248]\u001b[0m Trial 0 finished with value: 0.8160445188614203 and parameters: {'min_child_weight': 3, 'gamma': 1.0, 'subsample': 1.0, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 0 with value: 0.8160445188614203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:34,663]\u001b[0m Trial 1 finished with value: 0.8076627597754358 and parameters: {'min_child_weight': 4, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 4}. Best is trial 0 with value: 0.8160445188614203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:35,100]\u001b[0m Trial 2 finished with value: 0.8188318723529993 and parameters: {'min_child_weight': 2, 'gamma': 0.8, 'subsample': 0.7, 'colsample_bytree': 1.0, 'max_depth': 5}. Best is trial 2 with value: 0.8188318723529993.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:35,468]\u001b[0m Trial 3 finished with value: 0.8244656751699004 and parameters: {'min_child_weight': 5, 'gamma': 0.9, 'subsample': 1.0, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 3 with value: 0.8244656751699004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:36,114]\u001b[0m Trial 4 finished with value: 0.8104501132670145 and parameters: {'min_child_weight': 5, 'gamma': 0.1, 'subsample': 0.5, 'colsample_bytree': 0.9, 'max_depth': 7}. Best is trial 3 with value: 0.8244656751699004.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:36,727]\u001b[0m Trial 5 finished with value: 0.8034177090515119 and parameters: {'min_child_weight': 4, 'gamma': 1.0, 'subsample': 0.7, 'colsample_bytree': 0.8, 'max_depth': 7}. Best is trial 3 with value: 0.8244656751699004.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:37,314]\u001b[0m Trial 6 finished with value: 0.8286811779769525 and parameters: {'min_child_weight': 2, 'gamma': 0.6, 'subsample': 1.0, 'colsample_bytree': 0.8, 'max_depth': 6}. Best is trial 6 with value: 0.8286811779769525.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:37,949]\u001b[0m Trial 7 finished with value: 0.8272333300502315 and parameters: {'min_child_weight': 2, 'gamma': 0.6, 'subsample': 0.8, 'colsample_bytree': 1.0, 'max_depth': 6}. Best is trial 6 with value: 0.8286811779769525.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:38,751]\u001b[0m Trial 8 finished with value: 0.8090613611740372 and parameters: {'min_child_weight': 5, 'gamma': 0.6, 'subsample': 1.0, 'colsample_bytree': 0.7, 'max_depth': 8}. Best is trial 6 with value: 0.8286811779769525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:39,255]\u001b[0m Trial 9 finished with value: 0.8062444597655866 and parameters: {'min_child_weight': 5, 'gamma': 0.30000000000000004, 'subsample': 0.7, 'colsample_bytree': 0.6, 'max_depth': 10}. Best is trial 6 with value: 0.8286811779769525.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:40,360]\u001b[0m Trial 10 finished with value: 0.821619225844578 and parameters: {'min_child_weight': 1, 'gamma': 0.4, 'subsample': 0.9, 'colsample_bytree': 0.8, 'max_depth': 10}. Best is trial 6 with value: 0.8286811779769525.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:40,885]\u001b[0m Trial 11 finished with value: 0.8202501723628485 and parameters: {'min_child_weight': 1, 'gamma': 0.6, 'subsample': 0.5, 'colsample_bytree': 1.0, 'max_depth': 6}. Best is trial 6 with value: 0.8286811779769525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:41,689]\u001b[0m Trial 12 finished with value: 0.8314685314685315 and parameters: {'min_child_weight': 2, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 8}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:42,349]\u001b[0m Trial 13 finished with value: 0.8272825765783512 and parameters: {'min_child_weight': 2, 'gamma': 0.4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 9}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:42,949]\u001b[0m Trial 14 finished with value: 0.8244558258642766 and parameters: {'min_child_weight': 3, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 8}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:43,613]\u001b[0m Trial 15 finished with value: 0.8244558258642766 and parameters: {'min_child_weight': 2, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.8, 'max_depth': 8}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:44,300]\u001b[0m Trial 16 finished with value: 0.8272530286614794 and parameters: {'min_child_weight': 1, 'gamma': 0.7000000000000001, 'subsample': 1.0, 'colsample_bytree': 0.7, 'max_depth': 5}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:45,180]\u001b[0m Trial 17 finished with value: 0.8230473751600511 and parameters: {'min_child_weight': 3, 'gamma': 0.4, 'subsample': 0.8, 'colsample_bytree': 0.9, 'max_depth': 9}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:45,985]\u001b[0m Trial 18 finished with value: 0.8272628779671033 and parameters: {'min_child_weight': 2, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.8, 'max_depth': 7}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:46,722]\u001b[0m Trial 19 finished with value: 0.8230079779375554 and parameters: {'min_child_weight': 1, 'gamma': 0.7000000000000001, 'subsample': 0.6, 'colsample_bytree': 0.7, 'max_depth': 5}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:47,585]\u001b[0m Trial 20 finished with value: 0.8258544272628778 and parameters: {'min_child_weight': 2, 'gamma': 0.30000000000000004, 'subsample': 1.0, 'colsample_bytree': 0.9, 'max_depth': 9}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:48,153]\u001b[0m Trial 21 finished with value: 0.8272825765783512 and parameters: {'min_child_weight': 2, 'gamma': 0.4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 9}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:48,769]\u001b[0m Trial 22 finished with value: 0.8314685314685315 and parameters: {'min_child_weight': 2, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 8}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:49,266]\u001b[0m Trial 23 finished with value: 0.8230572244656752 and parameters: {'min_child_weight': 3, 'gamma': 0.7000000000000001, 'subsample': 0.8, 'colsample_bytree': 1.0, 'max_depth': 8}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:49,749]\u001b[0m Trial 24 finished with value: 0.8258347286516301 and parameters: {'min_child_weight': 1, 'gamma': 0.5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'max_depth': 6}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:50,255]\u001b[0m Trial 25 finished with value: 0.8230670737712991 and parameters: {'min_child_weight': 2, 'gamma': 0.30000000000000004, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 7}. Best is trial 12 with value: 0.8314685314685315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:50,695]\u001b[0m Trial 26 finished with value: 0.8328375849502612 and parameters: {'min_child_weight': 3, 'gamma': 0.5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'max_depth': 8}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:51,128]\u001b[0m Trial 27 finished with value: 0.8174037230375258 and parameters: {'min_child_weight': 4, 'gamma': 0.5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'max_depth': 8}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:51,551]\u001b[0m Trial 28 finished with value: 0.825844577957254 and parameters: {'min_child_weight': 3, 'gamma': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'max_depth': 10}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:52,007]\u001b[0m Trial 29 finished with value: 0.8118388653599921 and parameters: {'min_child_weight': 3, 'gamma': 0.5, 'subsample': 0.7, 'colsample_bytree': 0.9, 'max_depth': 9}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:52,359]\u001b[0m Trial 30 finished with value: 0.8006008076430613 and parameters: {'min_child_weight': 4, 'gamma': 0.4, 'subsample': 0.6, 'colsample_bytree': 0.8, 'max_depth': 8}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:52,813]\u001b[0m Trial 31 finished with value: 0.8258741258741258 and parameters: {'min_child_weight': 3, 'gamma': 0.6, 'subsample': 0.9, 'colsample_bytree': 0.8, 'max_depth': 7}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:53,240]\u001b[0m Trial 32 finished with value: 0.8300797793755539 and parameters: {'min_child_weight': 2, 'gamma': 0.7000000000000001, 'subsample': 1.0, 'colsample_bytree': 0.8, 'max_depth': 6}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:53,747]\u001b[0m Trial 33 finished with value: 0.8202600216684723 and parameters: {'min_child_weight': 2, 'gamma': 0.8, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 7}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:54,204]\u001b[0m Trial 34 finished with value: 0.8244853737811484 and parameters: {'min_child_weight': 3, 'gamma': 0.7000000000000001, 'subsample': 0.8, 'colsample_bytree': 0.7, 'max_depth': 8}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:54,569]\u001b[0m Trial 35 finished with value: 0.8230572244656752 and parameters: {'min_child_weight': 2, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:55,014]\u001b[0m Trial 36 finished with value: 0.8146754653796908 and parameters: {'min_child_weight': 3, 'gamma': 0.9, 'subsample': 0.9, 'colsample_bytree': 0.8, 'max_depth': 5}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:55,554]\u001b[0m Trial 37 finished with value: 0.8258544272628778 and parameters: {'min_child_weight': 2, 'gamma': 0.7000000000000001, 'subsample': 1.0, 'colsample_bytree': 0.9, 'max_depth': 7}. Best is trial 26 with value: 0.8328375849502612.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:56,081]\u001b[0m Trial 38 finished with value: 0.8342657342657344 and parameters: {'min_child_weight': 1, 'gamma': 0.6, 'subsample': 0.7, 'colsample_bytree': 1.0, 'max_depth': 6}. Best is trial 38 with value: 0.8342657342657344.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:56,693]\u001b[0m Trial 39 finished with value: 0.8188121737417513 and parameters: {'min_child_weight': 1, 'gamma': 0.6, 'subsample': 0.6, 'colsample_bytree': 1.0, 'max_depth': 9}. Best is trial 38 with value: 0.8342657342657344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:57,096]\u001b[0m Trial 40 finished with value: 0.8019797104304146 and parameters: {'min_child_weight': 4, 'gamma': 0.5, 'subsample': 0.7, 'colsample_bytree': 1.0, 'max_depth': 4}. Best is trial 38 with value: 0.8342657342657344.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:57,676]\u001b[0m Trial 41 finished with value: 0.825824879346006 and parameters: {'min_child_weight': 1, 'gamma': 0.6, 'subsample': 0.7, 'colsample_bytree': 0.9, 'max_depth': 6}. Best is trial 38 with value: 0.8342657342657344.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:58,177]\u001b[0m Trial 42 finished with value: 0.8230276765488032 and parameters: {'min_child_weight': 2, 'gamma': 0.6, 'subsample': 0.7, 'colsample_bytree': 1.0, 'max_depth': 6}. Best is trial 38 with value: 0.8342657342657344.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:58,718]\u001b[0m Trial 43 finished with value: 0.8244262779474048 and parameters: {'min_child_weight': 1, 'gamma': 0.5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'max_depth': 7}. Best is trial 38 with value: 0.8342657342657344.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:59,117]\u001b[0m Trial 44 finished with value: 0.8370530877573131 and parameters: {'min_child_weight': 2, 'gamma': 0.7000000000000001, 'subsample': 0.8, 'colsample_bytree': 0.8, 'max_depth': 5}. Best is trial 44 with value: 0.8370530877573131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:59,473]\u001b[0m Trial 45 finished with value: 0.837082635674185 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.9, 'max_depth': 3}. Best is trial 45 with value: 0.837082635674185.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:40:59,820]\u001b[0m Trial 46 finished with value: 0.8384812370727863 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.7, 'max_depth': 3}. Best is trial 46 with value: 0.8384812370727863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:00,126]\u001b[0m Trial 47 finished with value: 0.8357234314980794 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 46 with value: 0.8384812370727863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:00,439]\u001b[0m Trial 48 finished with value: 0.8356643356643356 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.7, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 46 with value: 0.8384812370727863.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:00,746]\u001b[0m Trial 49 finished with value: 0.8357234314980794 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 46 with value: 0.8384812370727863.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:01,053]\u001b[0m Trial 50 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:01,356]\u001b[0m Trial 51 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:01,651]\u001b[0m Trial 52 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:02,023]\u001b[0m Trial 53 finished with value: 0.8370727863685611 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:02,308]\u001b[0m Trial 54 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:02,620]\u001b[0m Trial 55 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:02,939]\u001b[0m Trial 56 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:03,224]\u001b[0m Trial 57 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:03,609]\u001b[0m Trial 58 finished with value: 0.8286417807544568 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.7, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:03,888]\u001b[0m Trial 59 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:04,211]\u001b[0m Trial 60 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:04,534]\u001b[0m Trial 61 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:04,862]\u001b[0m Trial 62 finished with value: 0.8314192849404117 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:05,183]\u001b[0m Trial 63 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:05,475]\u001b[0m Trial 64 finished with value: 0.8357234314980794 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:05,852]\u001b[0m Trial 65 finished with value: 0.8314192849404117 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:06,262]\u001b[0m Trial 66 finished with value: 0.8314882300797795 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.6, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:06,568]\u001b[0m Trial 67 finished with value: 0.8160346695557962 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.7, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:06,870]\u001b[0m Trial 68 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:07,255]\u001b[0m Trial 69 finished with value: 0.8370727863685611 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:07,564]\u001b[0m Trial 70 finished with value: 0.8301093272924259 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.9, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:07,927]\u001b[0m Trial 71 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:08,258]\u001b[0m Trial 72 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:08,580]\u001b[0m Trial 73 finished with value: 0.8314980793854033 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:08,900]\u001b[0m Trial 74 finished with value: 0.8314882300797792 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:09,318]\u001b[0m Trial 75 finished with value: 0.8314192849404117 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:09,652]\u001b[0m Trial 76 finished with value: 0.8356643356643356 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.7, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:10,037]\u001b[0m Trial 77 finished with value: 0.841288289175613 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:10,412]\u001b[0m Trial 78 finished with value: 0.8314882300797792 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:10,715]\u001b[0m Trial 79 finished with value: 0.834324830099478 and parameters: {'min_child_weight': 2, 'gamma': 0.8, 'subsample': 0.9, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:11,096]\u001b[0m Trial 80 finished with value: 0.8342657342657344 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:11,421]\u001b[0m Trial 81 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:11,728]\u001b[0m Trial 82 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:12,058]\u001b[0m Trial 83 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:12,397]\u001b[0m Trial 84 finished with value: 0.8314980793854033 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:12,701]\u001b[0m Trial 85 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:13,021]\u001b[0m Trial 86 finished with value: 0.8314980793854033 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:13,365]\u001b[0m Trial 87 finished with value: 0.8286417807544568 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.7, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:13,673]\u001b[0m Trial 88 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:13,961]\u001b[0m Trial 89 finished with value: 0.8231261696050429 and parameters: {'min_child_weight': 2, 'gamma': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:14,320]\u001b[0m Trial 90 finished with value: 0.8370727863685611 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:14,654]\u001b[0m Trial 91 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:14,937]\u001b[0m Trial 92 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:15,309]\u001b[0m Trial 93 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:15,647]\u001b[0m Trial 94 finished with value: 0.8315079286910272 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:15,946]\u001b[0m Trial 95 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:16,322]\u001b[0m Trial 96 finished with value: 0.8342657342657344 and parameters: {'min_child_weight': 1, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n",
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:16,631]\u001b[0m Trial 97 finished with value: 0.8427065891854625 and parameters: {'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-01-03 21:41:16,950]\u001b[0m Trial 98 finished with value: 0.8314586821629076 and parameters: {'min_child_weight': 1, 'gamma': 0.8, 'subsample': 0.7, 'colsample_bytree': 0.6, 'max_depth': 3}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t/.pyenv/versions/3.8.5/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:41:17,317]\u001b[0m Trial 99 finished with value: 0.8244558258642766 and parameters: {'min_child_weight': 2, 'gamma': 1.0, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 4}. Best is trial 50 with value: 0.8427065891854625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'min_child_weight': 1, 'gamma': 0.9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'max_depth': 3}\n",
      "0.8427065891854625\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param_grid_xgb = {\n",
    "        'min_child_weight': trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "        'gamma': trial.suggest_discrete_uniform(\"gamma\", 0.1, 1.0, 0.1),\n",
    "        'subsample': trial.suggest_discrete_uniform(\"subsample\", 0.5, 1.0, 0.1),\n",
    "        'colsample_bytree': trial.suggest_discrete_uniform(\"colsample_bytree\", 0.5, 1.0, 0.1),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"random_state\": 0\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param_grid_xgb)\n",
    "    \n",
    "    # 5-Fold CV / Accuracy でモデルを評価する\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n",
    "    # 最小化なので 1.0 からスコアを引く\n",
    "    return scores['test_score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "xgb_best_param = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:46:13,842]\u001b[0m A new study created in memory with name: no-name-09bb5cc4-227d-47e4-a0c5-016c6151da54\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:14,074]\u001b[0m Trial 0 finished with value: 0.8217078695951935 and parameters: {'num_leaves': 3, 'learning_rate': 0.1985881992770371, 'max_depth': 8}. Best is trial 0 with value: 0.8217078695951935.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:14,264]\u001b[0m Trial 1 finished with value: 0.7780458977642077 and parameters: {'num_leaves': 10, 'learning_rate': 0.002847060106271885, 'max_depth': 5}. Best is trial 0 with value: 0.8217078695951935.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:14,393]\u001b[0m Trial 2 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 6, 'learning_rate': 1.1925724306712266e-06, 'max_depth': 6}. Best is trial 0 with value: 0.8217078695951935.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:14,549]\u001b[0m Trial 3 finished with value: 0.8202501723628485 and parameters: {'num_leaves': 6, 'learning_rate': 0.2717385998493675, 'max_depth': 5}. Best is trial 0 with value: 0.8217078695951935.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:14,753]\u001b[0m Trial 4 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 6, 'learning_rate': 5.454056906764525e-05, 'max_depth': 3}. Best is trial 0 with value: 0.8217078695951935.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:14,881]\u001b[0m Trial 5 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 5, 'learning_rate': 5.5366557718410705e-05, 'max_depth': 6}. Best is trial 0 with value: 0.8217078695951935.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,011]\u001b[0m Trial 6 finished with value: 0.8272825765783512 and parameters: {'num_leaves': 6, 'learning_rate': 0.08819719799938629, 'max_depth': 10}. Best is trial 6 with value: 0.8272825765783512.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,132]\u001b[0m Trial 7 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 4, 'learning_rate': 0.00038937237752476603, 'max_depth': 3}. Best is trial 6 with value: 0.8272825765783512.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,296]\u001b[0m Trial 8 finished with value: 0.830089628681178 and parameters: {'num_leaves': 9, 'learning_rate': 0.04155010372979408, 'max_depth': 8}. Best is trial 8 with value: 0.830089628681178.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,427]\u001b[0m Trial 9 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 7, 'learning_rate': 2.0584866630019103e-06, 'max_depth': 5}. Best is trial 8 with value: 0.830089628681178.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,591]\u001b[0m Trial 10 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 10, 'learning_rate': 1.4230433141861197e-08, 'max_depth': 9}. Best is trial 8 with value: 0.830089628681178.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,752]\u001b[0m Trial 11 finished with value: 0.8343149807938539 and parameters: {'num_leaves': 8, 'learning_rate': 0.01590102043486528, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:15,904]\u001b[0m Trial 12 finished with value: 0.8090121146459175 and parameters: {'num_leaves': 8, 'learning_rate': 0.008647191978349287, 'max_depth': 8}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:16,050]\u001b[0m Trial 13 finished with value: 0.8328966807840047 and parameters: {'num_leaves': 9, 'learning_rate': 0.013438703013695997, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:16,189]\u001b[0m Trial 14 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 8, 'learning_rate': 0.0015748609210148108, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:16,353]\u001b[0m Trial 15 finished with value: 0.8188417216586231 and parameters: {'num_leaves': 9, 'learning_rate': 0.6574253209459353, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:16,567]\u001b[0m Trial 16 finished with value: 0.8329065300896286 and parameters: {'num_leaves': 8, 'learning_rate': 0.016125441634286922, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:16,848]\u001b[0m Trial 17 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 8, 'learning_rate': 0.0004857441249732006, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:17,143]\u001b[0m Trial 18 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 7, 'learning_rate': 1.003817668514799e-05, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:17,330]\u001b[0m Trial 19 finished with value: 0.8314783807741554 and parameters: {'num_leaves': 8, 'learning_rate': 0.017568553958631602, 'max_depth': 7}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:17,494]\u001b[0m Trial 20 finished with value: 0.814616369545947 and parameters: {'num_leaves': 7, 'learning_rate': 0.9545761556039652, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:17,673]\u001b[0m Trial 21 finished with value: 0.8090121146459175 and parameters: {'num_leaves': 9, 'learning_rate': 0.0085910367481481, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:17,836]\u001b[0m Trial 22 finished with value: 0.8315079286910274 and parameters: {'num_leaves': 9, 'learning_rate': 0.04292272973888023, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:18,001]\u001b[0m Trial 23 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 10, 'learning_rate': 0.0018347034977587264, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:18,173]\u001b[0m Trial 24 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 8, 'learning_rate': 0.00028279087614737426, 'max_depth': 8}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:18,343]\u001b[0m Trial 25 finished with value: 0.8005909583374372 and parameters: {'num_leaves': 9, 'learning_rate': 0.006447446958845956, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:18,522]\u001b[0m Trial 26 finished with value: 0.8258642765685019 and parameters: {'num_leaves': 7, 'learning_rate': 0.09639152716944091, 'max_depth': 7}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:18,812]\u001b[0m Trial 27 finished with value: 0.8160248202501723 and parameters: {'num_leaves': 10, 'learning_rate': 0.9412873165311161, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:18,955]\u001b[0m Trial 28 finished with value: 0.8258642765685019 and parameters: {'num_leaves': 8, 'learning_rate': 0.029853239501825942, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:19,128]\u001b[0m Trial 29 finished with value: 0.8159854230276764 and parameters: {'num_leaves': 9, 'learning_rate': 0.34006708977132044, 'max_depth': 8}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:19,249]\u001b[0m Trial 30 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 3, 'learning_rate': 0.0009060346406666058, 'max_depth': 7}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:19,779]\u001b[0m Trial 31 finished with value: 0.8272727272727274 and parameters: {'num_leaves': 9, 'learning_rate': 0.09869666029047638, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:19,941]\u001b[0m Trial 32 finished with value: 0.7850980005909584 and parameters: {'num_leaves': 10, 'learning_rate': 0.003931807935450061, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:20,098]\u001b[0m Trial 33 finished with value: 0.83006993006993 and parameters: {'num_leaves': 9, 'learning_rate': 0.02205355803899001, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:20,257]\u001b[0m Trial 34 finished with value: 0.8188121737417513 and parameters: {'num_leaves': 8, 'learning_rate': 0.21617529145749015, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:20,429]\u001b[0m Trial 35 finished with value: 0.8286811779769525 and parameters: {'num_leaves': 7, 'learning_rate': 0.0555401571693745, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:20,589]\u001b[0m Trial 36 finished with value: 0.825844577957254 and parameters: {'num_leaves': 10, 'learning_rate': 0.011044250864022252, 'max_depth': 4}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:21,181]\u001b[0m Trial 37 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 9, 'learning_rate': 2.2279139447618e-08, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:21,620]\u001b[0m Trial 38 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 8, 'learning_rate': 0.00018155373851416095, 'max_depth': 8}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:21,993]\u001b[0m Trial 39 finished with value: 0.8300797793755539 and parameters: {'num_leaves': 6, 'learning_rate': 0.17978584665663044, 'max_depth': 9}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:22,346]\u001b[0m Trial 40 finished with value: 0.783709248497981 and parameters: {'num_leaves': 5, 'learning_rate': 0.0036776928325544522, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:22,520]\u001b[0m Trial 41 finished with value: 0.8314783807741554 and parameters: {'num_leaves': 8, 'learning_rate': 0.0207382777738436, 'max_depth': 6}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:23,093]\u001b[0m Trial 42 finished with value: 0.8258938244853737 and parameters: {'num_leaves': 9, 'learning_rate': 0.030862133249794865, 'max_depth': 6}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:23,470]\u001b[0m Trial 43 finished with value: 0.8328966807840048 and parameters: {'num_leaves': 8, 'learning_rate': 0.05304244611772628, 'max_depth': 6}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:23,670]\u001b[0m Trial 44 finished with value: 0.8244558258642766 and parameters: {'num_leaves': 7, 'learning_rate': 0.0720854265728743, 'max_depth': 5}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:23,845]\u001b[0m Trial 45 finished with value: 0.8118388653599921 and parameters: {'num_leaves': 8, 'learning_rate': 0.3519931711324902, 'max_depth': 5}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:24,290]\u001b[0m Trial 46 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 9, 'learning_rate': 0.002144396720923317, 'max_depth': 7}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:24,489]\u001b[0m Trial 47 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 10, 'learning_rate': 0.0008964648459344972, 'max_depth': 6}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:24,728]\u001b[0m Trial 48 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 8, 'learning_rate': 5.405285589533013e-05, 'max_depth': 4}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:24,890]\u001b[0m Trial 49 finished with value: 0.7977740569289865 and parameters: {'num_leaves': 7, 'learning_rate': 0.006801826199507804, 'max_depth': 8}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:25,073]\u001b[0m Trial 50 finished with value: 0.8230473751600511 and parameters: {'num_leaves': 9, 'learning_rate': 0.16982976114087253, 'max_depth': 10}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:25,252]\u001b[0m Trial 51 finished with value: 0.8314783807741554 and parameters: {'num_leaves': 8, 'learning_rate': 0.02020180323496603, 'max_depth': 7}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:25,425]\u001b[0m Trial 52 finished with value: 0.8343149807938539 and parameters: {'num_leaves': 8, 'learning_rate': 0.014919233542268212, 'max_depth': 6}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:25,597]\u001b[0m Trial 53 finished with value: 0.8259036737909978 and parameters: {'num_leaves': 8, 'learning_rate': 0.04055345565437875, 'max_depth': 6}. Best is trial 11 with value: 0.8343149807938539.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:25,773]\u001b[0m Trial 54 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 7, 'learning_rate': 0.012067987850801055, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:25,941]\u001b[0m Trial 55 finished with value: 0.7907318034078598 and parameters: {'num_leaves': 7, 'learning_rate': 0.005320885794652744, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:26,102]\u001b[0m Trial 56 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 6, 'learning_rate': 0.012058393487871282, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:26,263]\u001b[0m Trial 57 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 6, 'learning_rate': 0.012144534043806554, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:26,428]\u001b[0m Trial 58 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 5, 'learning_rate': 0.001685382228270556, 'max_depth': 4}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:26,606]\u001b[0m Trial 59 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 6, 'learning_rate': 0.0007198204350347304, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:26,829]\u001b[0m Trial 60 finished with value: 0.825844577957254 and parameters: {'num_leaves': 6, 'learning_rate': 0.009223677384506183, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:26,998]\u001b[0m Trial 61 finished with value: 0.83430513148823 and parameters: {'num_leaves': 6, 'learning_rate': 0.013995391991232784, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:27,172]\u001b[0m Trial 62 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 6, 'learning_rate': 0.012732465764335114, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:27,341]\u001b[0m Trial 63 finished with value: 0.7780458977642077 and parameters: {'num_leaves': 6, 'learning_rate': 0.003217232172630073, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:27,512]\u001b[0m Trial 64 finished with value: 0.8188220230473752 and parameters: {'num_leaves': 5, 'learning_rate': 0.01193158462451083, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:28,029]\u001b[0m Trial 65 finished with value: 0.7893135033980105 and parameters: {'num_leaves': 6, 'learning_rate': 0.005581662952428564, 'max_depth': 4}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:28,194]\u001b[0m Trial 66 finished with value: 0.7738500935684034 and parameters: {'num_leaves': 5, 'learning_rate': 0.002825121964896327, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:28,456]\u001b[0m Trial 67 finished with value: 0.83430513148823 and parameters: {'num_leaves': 6, 'learning_rate': 0.013914846823743252, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:28,613]\u001b[0m Trial 68 finished with value: 0.8245050723923963 and parameters: {'num_leaves': 4, 'learning_rate': 0.09581508866294547, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:28,821]\u001b[0m Trial 69 finished with value: 0.8300600807643062 and parameters: {'num_leaves': 6, 'learning_rate': 0.031730105564662194, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:28,989]\u001b[0m Trial 70 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 7, 'learning_rate': 0.0011019968135963577, 'max_depth': 4}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:29,155]\u001b[0m Trial 71 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 6, 'learning_rate': 0.013595791725105751, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:29,324]\u001b[0m Trial 72 finished with value: 0.7977445090121147 and parameters: {'num_leaves': 6, 'learning_rate': 0.007698494625055116, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:29,520]\u001b[0m Trial 73 finished with value: 0.8188712695754947 and parameters: {'num_leaves': 5, 'learning_rate': 0.0179518799080668, 'max_depth': 7}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:29,698]\u001b[0m Trial 74 finished with value: 0.8244656751699004 and parameters: {'num_leaves': 7, 'learning_rate': 0.11790440230411002, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:29,871]\u001b[0m Trial 75 finished with value: 0.7879050526937852 and parameters: {'num_leaves': 6, 'learning_rate': 0.003945851642029518, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:30,068]\u001b[0m Trial 76 finished with value: 0.8328868314783808 and parameters: {'num_leaves': 6, 'learning_rate': 0.024775640804205957, 'max_depth': 6}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:30,223]\u001b[0m Trial 77 finished with value: 0.8314783807741556 and parameters: {'num_leaves': 5, 'learning_rate': 0.4711663568083574, 'max_depth': 5}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:30,400]\u001b[0m Trial 78 finished with value: 0.8300797793755541 and parameters: {'num_leaves': 7, 'learning_rate': 0.0588776030392751, 'max_depth': 7}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:30,561]\u001b[0m Trial 79 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 6, 'learning_rate': 3.0554800441436666e-07, 'max_depth': 3}. Best is trial 54 with value: 0.8357037328868315.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:30,807]\u001b[0m Trial 80 finished with value: 0.8371121835910568 and parameters: {'num_leaves': 7, 'learning_rate': 0.012428483677791534, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:30,979]\u001b[0m Trial 81 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 7, 'learning_rate': 0.012006961144694529, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:31,155]\u001b[0m Trial 82 finished with value: 0.7907318034078598 and parameters: {'num_leaves': 7, 'learning_rate': 0.004907864692574518, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:31,323]\u001b[0m Trial 83 finished with value: 0.8244164286417808 and parameters: {'num_leaves': 7, 'learning_rate': 0.009524667798912331, 'max_depth': 4}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:31,492]\u001b[0m Trial 84 finished with value: 0.7738500935684034 and parameters: {'num_leaves': 7, 'learning_rate': 0.0025433706389917927, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:31,665]\u001b[0m Trial 85 finished with value: 0.8216487737614496 and parameters: {'num_leaves': 7, 'learning_rate': 0.03523630090910657, 'max_depth': 4}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:31,831]\u001b[0m Trial 86 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 7, 'learning_rate': 0.0004971224496530267, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:31,995]\u001b[0m Trial 87 finished with value: 0.6165763813651137 and parameters: {'num_leaves': 6, 'learning_rate': 0.0014011953292942796, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:32,166]\u001b[0m Trial 88 finished with value: 0.8272825765783512 and parameters: {'num_leaves': 7, 'learning_rate': 0.05279265259167309, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:32,334]\u001b[0m Trial 89 finished with value: 0.8300994779868021 and parameters: {'num_leaves': 6, 'learning_rate': 0.14254739102343353, 'max_depth': 6}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:32,503]\u001b[0m Trial 90 finished with value: 0.8258544272628778 and parameters: {'num_leaves': 7, 'learning_rate': 0.023755480508059874, 'max_depth': 4}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:32,740]\u001b[0m Trial 91 finished with value: 0.8286713286713286 and parameters: {'num_leaves': 6, 'learning_rate': 0.014559115690500411, 'max_depth': 6}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:32,905]\u001b[0m Trial 92 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 6, 'learning_rate': 0.012612580774598753, 'max_depth': 6}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:33,076]\u001b[0m Trial 93 finished with value: 0.807593814636068 and parameters: {'num_leaves': 6, 'learning_rate': 0.008468567967557504, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:33,237]\u001b[0m Trial 94 finished with value: 0.7851078498965823 and parameters: {'num_leaves': 5, 'learning_rate': 0.005993577822049591, 'max_depth': 6}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:33,399]\u001b[0m Trial 95 finished with value: 0.830089628681178 and parameters: {'num_leaves': 6, 'learning_rate': 0.0766717996413257, 'max_depth': 5}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:33,568]\u001b[0m Trial 96 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 7, 'learning_rate': 0.011456097197526981, 'max_depth': 6}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:33,747]\u001b[0m Trial 97 finished with value: 0.8216487737614498 and parameters: {'num_leaves': 7, 'learning_rate': 0.03681831102763222, 'max_depth': 6}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:33,911]\u001b[0m Trial 98 finished with value: 0.8357037328868315 and parameters: {'num_leaves': 6, 'learning_rate': 0.011787416296569845, 'max_depth': 7}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:46:34,079]\u001b[0m Trial 99 finished with value: 0.7879050526937852 and parameters: {'num_leaves': 6, 'learning_rate': 0.004005207107988369, 'max_depth': 7}. Best is trial 80 with value: 0.8371121835910568.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 7, 'learning_rate': 0.012428483677791534, 'max_depth': 5}\n",
      "0.8371121835910568\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param_grid_lgb = {\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1.0),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"random_state\": 0\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**param_grid_lgb)\n",
    "    \n",
    "    # 5-Fold CV / Accuracy でモデルを評価する\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n",
    "    # 最小化なので 1.0 からスコアを引く\n",
    "    return scores['test_score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "lgb_best_param = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:47:29,163]\u001b[0m A new study created in memory with name: no-name-2dbecf1e-36a6-42c1-8d13-a0b4ca7da468\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:29,372]\u001b[0m Trial 0 finished with value: 0.8244361272530287 and parameters: {'C': 38}. Best is trial 0 with value: 0.8244361272530287.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:29,506]\u001b[0m Trial 1 finished with value: 0.8286614793657048 and parameters: {'C': 1}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:29,652]\u001b[0m Trial 2 finished with value: 0.8230375258544272 and parameters: {'C': 82}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:29,792]\u001b[0m Trial 3 finished with value: 0.8244558258642766 and parameters: {'C': 25}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:29,930]\u001b[0m Trial 4 finished with value: 0.8244558258642766 and parameters: {'C': 25}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:30,067]\u001b[0m Trial 5 finished with value: 0.8244459765586527 and parameters: {'C': 36}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:30,205]\u001b[0m Trial 6 finished with value: 0.8230375258544272 and parameters: {'C': 73}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:30,341]\u001b[0m Trial 7 finished with value: 0.8244361272530287 and parameters: {'C': 43}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:30,480]\u001b[0m Trial 8 finished with value: 0.8244459765586527 and parameters: {'C': 79}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:30,619]\u001b[0m Trial 9 finished with value: 0.8230375258544272 and parameters: {'C': 80}. Best is trial 1 with value: 0.8286614793657048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.8286614793657048\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param_grid_lr = {\n",
    "        'C' : trial.suggest_int(\"C\", 1, 100),\n",
    "        \"random_state\": 0\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(**param_grid_lr)\n",
    "    \n",
    "    # 5-Fold CV / Accuracy でモデルを評価する\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n",
    "    # 最小化なので 1.0 からスコアを引く\n",
    "    return scores['test_score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "lr_best_param = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ・ SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:47:38,183]\u001b[0m A new study created in memory with name: no-name-e9ae5380-92c3-4dc5-b67d-5486b07554bc\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:38,321]\u001b[0m Trial 0 finished with value: 0.8342854328769821 and parameters: {'C': 90, 'gamma': 0.02122463917423607}. Best is trial 0 with value: 0.8342854328769821.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:38,457]\u001b[0m Trial 1 finished with value: 0.8371023342854329 and parameters: {'C': 176, 'gamma': 0.00022120606768893459}. Best is trial 1 with value: 0.8371023342854329.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:38,579]\u001b[0m Trial 2 finished with value: 0.8427361371023345 and parameters: {'C': 83, 'gamma': 0.015183597281370736}. Best is trial 2 with value: 0.8427361371023345.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:38,707]\u001b[0m Trial 3 finished with value: 0.8300896286811781 and parameters: {'C': 194, 'gamma': 0.0015389201018484863}. Best is trial 2 with value: 0.8427361371023345.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:38,806]\u001b[0m Trial 4 finished with value: 0.8244459765586527 and parameters: {'C': 183, 'gamma': 0.4845169006647052}. Best is trial 2 with value: 0.8427361371023345.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:38,901]\u001b[0m Trial 5 finished with value: 0.8160642174726682 and parameters: {'C': 182, 'gamma': 0.09662337856836622}. Best is trial 2 with value: 0.8427361371023345.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:39,013]\u001b[0m Trial 6 finished with value: 0.8427459864079584 and parameters: {'C': 175, 'gamma': 0.007849918311192377}. Best is trial 6 with value: 0.8427459864079584.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:39,102]\u001b[0m Trial 7 finished with value: 0.8174529695656456 and parameters: {'C': 199, 'gamma': 0.15774508366145143}. Best is trial 6 with value: 0.8427459864079584.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:39,192]\u001b[0m Trial 8 finished with value: 0.8314882300797795 and parameters: {'C': 85, 'gamma': 0.0006471105499470095}. Best is trial 6 with value: 0.8427459864079584.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:47:39,290]\u001b[0m Trial 9 finished with value: 0.8314980793854033 and parameters: {'C': 159, 'gamma': 0.0008204502878655152}. Best is trial 6 with value: 0.8427459864079584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 175, 'gamma': 0.007849918311192377}\n",
      "0.8427459864079584\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param_grid_svc = {\n",
    "        'C' : trial.suggest_int(\"C\", 50, 200),\n",
    "        'gamma': trial.suggest_loguniform(\"gamma\", 1e-4, 1.0),\n",
    "        \"random_state\": 0,\n",
    "        'kernel': 'rbf'\n",
    "    }\n",
    "\n",
    "    model = SVC(**param_grid_svc)\n",
    "    \n",
    "    # 5-Fold CV / Accuracy でモデルを評価する\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n",
    "    # 最小化なので 1.0 からスコアを引く\n",
    "    return scores['test_score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "svc_best_param = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 汎化性能検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ RandomForestClassifier\n",
      "mean:0.8271420500910175, std:0.01170254590643617\n",
      "====================\n",
      "■ XGBClassifier\n",
      "[21:49:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:49:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:49:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:49:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:49:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "mean:0.8136902893729208, std:0.010922866328636162\n",
      "====================\n",
      "■ LGBMClassifier\n",
      "mean:0.8192706044818279, std:0.03411615247033993\n",
      "====================\n",
      "■ LogisticRegression\n",
      "mean:0.8204067541271733, std:0.018289612975143935\n",
      "====================\n",
      "■ SVC\n",
      "mean:0.8125290314481199, std:0.02742458504271426\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold CV / Accuracy でモデルを評価する\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "rfc_best = RandomForestClassifier(**rfc_best_param)\n",
    "print('■ RandomForestClassifier')\n",
    "scores = cross_validate(rfc_best, X=train_feature, y=train_tagert, cv=kf)\n",
    "print(f'mean:{scores[\"test_score\"].mean()}, std:{scores[\"test_score\"].std()}')\n",
    "print('='*20)\n",
    "\n",
    "xgb_best = XGBClassifier(**xgb_best_param)\n",
    "print('■ XGBClassifier')\n",
    "scores = cross_validate(xgb_best, X=train_feature, y=train_tagert, cv=kf)\n",
    "print(f'mean:{scores[\"test_score\"].mean()}, std:{scores[\"test_score\"].std()}')\n",
    "print('='*20)\n",
    "\n",
    "lgb_best = LGBMClassifier(**lgb_best_param)\n",
    "print('■ LGBMClassifier')\n",
    "scores = cross_validate(lgb_best, X=train_feature, y=train_tagert, cv=kf)\n",
    "print(f'mean:{scores[\"test_score\"].mean()}, std:{scores[\"test_score\"].std()}')\n",
    "print('='*20)\n",
    "\n",
    "lr_best = LogisticRegression(**lr_best_param)\n",
    "print('■ LogisticRegression')\n",
    "scores = cross_validate(lr_best, X=train_feature, y=train_tagert, cv=kf)\n",
    "print(f'mean:{scores[\"test_score\"].mean()}, std:{scores[\"test_score\"].std()}')\n",
    "print('='*20)\n",
    "\n",
    "svc_best = SVC(**svc_best_param)\n",
    "print('■ SVC')\n",
    "scores = cross_validate(svc_best, X=train_feature, y=train_tagert, cv=kf)\n",
    "print(f'mean:{scores[\"test_score\"].mean()}, std:{scores[\"test_score\"].std()}')\n",
    "print('='*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・ VotingClassifer\n",
    "多数決モデルを試しに実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ VotingClassifier\n",
      "[21:50:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:50:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:50:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:50:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:50:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "mean:0.8293829640323895, std:0.02222389825956032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# voting に使う分類器を用意する\n",
    "estimators = [\n",
    "    ('rfc', RandomForestClassifier(**rfc_best_param)),\n",
    "    ('xgb', XGBClassifier(**xgb_best_param)),\n",
    "    ('lgb', LGBMClassifier(**lgb_best_param)),\n",
    "    ('lr', LogisticRegression(**lr_best_param)),\n",
    "    ('svc', SVC(**lr_best_param))\n",
    "]\n",
    "voting = VotingClassifier(estimators)\n",
    "\n",
    "print('■ VotingClassifier')\n",
    "scores = cross_validate(voting, X=train_feature, y=train_tagert, cv=kf)\n",
    "print(f'mean:{scores[\"test_score\"].mean()}, std:{scores[\"test_score\"].std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚢 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "rfc_best = RandomForestClassifier(**rfc_best_param)\n",
    "rfc_best.fit(train_feature, train_tagert)\n",
    "# XGBoost\n",
    "xgb_best = XGBClassifier(**xgb_best_param)\n",
    "xgb_best.fit(train_feature, train_tagert)\n",
    "# LightGBM\n",
    "lgb_best = LGBMClassifier(**lgb_best_param)\n",
    "lgb_best.fit(train_feature, train_tagert)\n",
    "# LogisticRegression\n",
    "lr_best = LogisticRegression(**lr_best_param)\n",
    "lr_best.fit(train_feature, train_tagert)\n",
    "# SVC\n",
    "svc_best = SVC(**svc_best_param)\n",
    "svc_best.fit(train_feature, train_tagert)\n",
    "# 推論\n",
    "pred = {\n",
    "    'rfc': rfc_best.predict(test_feature),\n",
    "    'xgb': xgb_best.predict(test_feature),\n",
    "    'lgb': lgb_best.predict(test_feature),\n",
    "    'lr': lr_best.predict(test_feature),\n",
    "    'svc': svc_best.predict(test_feature)\n",
    "}\n",
    "# ファイル出力\n",
    "for key, value in pred.items():\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(test.PassengerId, columns=['PassengerId']).reset_index(drop=True),\n",
    "            pd.DataFrame(value, columns=['Survived'])\n",
    "        ],\n",
    "        axis=1\n",
    "    ).to_csv(f'output_{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
